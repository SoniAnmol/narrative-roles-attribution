"""
This script contains methods for performing topic modeling using LDA.
"""

# ----------------------------- Import libraries ----------------------------- #
import pandas as pd
from pprint import pprint
import gensim.corpora as corpora
from gensim.models import CoherenceModel
from gensim.utils import simple_preprocess
from gensim.models.ldamodel import LdaModel
from nltk.corpus import stopwords
import pyLDAvis
import pyLDAvis.gensim_models as gensimvis
from translate_articles import detect_language


# ------------------------------ Define methods ------------------------------ #
def perform_lda(text, nlp_model="en_core_web_trf", num_topics=5):
    """
    Perform Latent Dirichlet Allocation (LDA) on the given text data and visualize the topics.

    Parameters:
        text (list): A list of preprocessed text data.
        nlp_model (str): The name of the spaCy language model to be used. Default is "en_core_web_trf".
        num_topics (int): The number of topics to be generated by the LDA model. Default is 5.

    Returns:
        pyLDAvis.PreparedData: An object for visualizing the LDA model.
    """
    # Create Dictionary
    id2word = corpora.Dictionary(processed_texts)
    # Create Corpus
    texts = processed_texts
    # Term Document Frequency
    corpus = [id2word.doc2bow(text) for text in texts]
    # Build LDA model
    lda_model = LdaModel(
        corpus=corpus,
        id2word=id2word,
        num_topics=num_topics,
        random_state=42,
        passes=10,
        alpha="auto",
        per_word_topics=True,
    )
    pprint(lda_model.print_topics())
    coherence_model_lda = CoherenceModel(model=lda_model, texts=processed_texts, dictionary=id2word, coherence="c_v")
    coherence_lda = coherence_model_lda.get_coherence()
    print("Coherence Score: ", coherence_lda)
    return gensimvis.prepare(lda_model, corpus, id2word)


def preprocess_text(doc, additional_stopwords=None):
    """
    Preprocess a single document by tokenizing and removing stop words.

    Parameters:
        doc (str): A single text document to be preprocessed.
        additional_stopwords (list): A list of additional stop words to be removed. Default is None.

    Returns:
        str: A preprocessed text document as a single string.
    """
    stop_words = set(stopwords.words("english"))
    if additional_stopwords:
        stop_words.update(additional_stopwords)

    # Tokenize and remove stop words
    tokens = simple_preprocess(doc, deacc=True)
    filtered_tokens = [word for word in tokens if word not in stop_words]

    return " ".join(filtered_tokens)


# ----------------------------------- main ----------------------------------- #
if __name__ == "__main__":
    # Read files
    df = pd.read_csv("data/alluvione emilia-romagna-2023-04-01-to-2024-03-01-translated.csv")

    # Filter the text which is not translated
    df["translated_lang"] = df.translated_text.apply(detect_language)
    df = df[df.translated_lang == "en"].reset_index(drop=True)

    # Define additional stop words
    additional_stopwords = ["also"]

    # Preprocess the text data
    processed_texts = preprocess_data(df.translated_text, additional_stopwords)

    # Perform LDA
    vis = perform_lda(processed_texts)

    # Visualize the topics
    pyLDAvis.save_html(vis, "figures/lda_vis.html")
    pyLDAvis.display(vis)
